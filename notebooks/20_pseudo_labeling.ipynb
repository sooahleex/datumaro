{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-Labeling for unlabeled dataset with zero-shot learned image-text embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce a new pseudo-labeling technique designed for unlabeled datasets. This feature leverages zero-shot learned image-text embeddings using the [CLIP (Contrastive Language-Image Pre-training)](https://github.com/openai/CLIP) model to propose labels for unlabeled data. By computing hash values of dataset items and predefined labels, we assign the most similar label to each item based on the calculated distance.\n",
    "\n",
    "### Key Features:\n",
    "- Utilizes CLIP to compute hash representations of both dataset items and labels.\n",
    "- Computes similarity between dataset items and a set of predefined labels to assign pseudo-labels.\n",
    "- Facilitates pseudo-labeling in semi-supervised learning tasks, particularly useful for unlabeled or partially labeled datasets.\n",
    "- Applies hashing techniques to efficiently compare embeddings.\n",
    "\n",
    "This method helps improve model performance in scenarios where labeled data is limited, by making use of the relationship between images and text to assign the best-fitting labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Overview\n",
    "\n",
    "The `PseudoLabeling` class is designed to assign pseudo-labels to items in a dataset based on their similarity to a set of predefined labels. It does this by extracting hash keys for both the dataset items and the labels using a CLIP-based Explorer object, and then calculating the similarity between these hashes.\n",
    "\n",
    "### Key Methods and Attributes:\n",
    "\n",
    "- **`__init__(self, extractor, labels=None, explorer=None)`**: Initializes the pseudo-labeling system. Takes an extractor (which provides dataset access), an optional list of labels, and an optional `Explorer` object for hashing. If labels are not provided, all available labels in the dataset are used.\n",
    "\n",
    "- **`transform_item(self, item)`**: Transforms a single dataset item by computing its hash key, comparing it to the label hashes, and assigning the most similar label as a pseudo-label.\n",
    "\n",
    "- **Attributes**:\n",
    "    - **`extractor`**: Provides access to dataset items and annotations.\n",
    "    - **`labels`**: Optional list of predefined label names.\n",
    "    - **`explorer`**: Optional CLIP-based Explorer object to compute hash keys for items and labels.\n",
    "    - **`_label_hashkeys`**: Stores hash keys for predefined labels, computed during initialization.\n",
    "\n",
    "This feature is especially useful for semi-supervised learning tasks where some items are unlabeled, and it can be easily integrated into workflows that involve large-scale datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before applying the pseudo-labeling feature, we need a suitable dataset to work with. For this notebook, we will use the **CIFAR-10** dataset for this notebook, which consists of 60,000 images across 10 classes. CIFAR-10 is a commonly used dataset for image classification tasks, making it ideal for evaluating the pseudo-labeling feature.\n",
    "\n",
    "You can download and extract CIFAR-10 using the following command:\n",
    "\n",
    "```bash\n",
    "# Download CIFAR-10 dataset\n",
    "!curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "# Extract the dataset\n",
    "!tar -xvzf cifar-10-python.tar.gz\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "Now that we have the dataset ready, let's walk through a basic example of how to use the `PseudoLabeling` feature to assign pseudo-labels to unlabeled items in the dataset.\n",
    "\n",
    "### Steps:\n",
    "1. Load the CIFAR-10 dataset using `Dataset.import_from()`.\n",
    "2. Define a list of 10 labels to use for pseudo-labeling.\n",
    "3. Apply the `pseudo_labeling` transformation to the dataset.\n",
    "4. View the transformed dataset and check the assigned pseudo-labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sooahlee/.pyenv/versions/3.11.9/envs/datum/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Failed to find dataset 'cifar' at 'cifar-100-python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatumaro\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Assuming the CIFAR-100 dataset has been loaded and extracted\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize the dataset extractor\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_from\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcifar-100-python\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcifar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Define the label list (CIFAR-10 classes)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m label_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mairplane\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautomobile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbird\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruck\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/local/sooahlee/datumaro/src/datumaro/components/dataset.py:834\u001b[0m, in \u001b[0;36mDataset.import_from\u001b[0;34m(cls, path, format, env, progress_reporter, error_policy, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m     importer \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mmake_importer(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging_disabled(log\u001b[38;5;241m.\u001b[39mINFO):\n\u001b[1;32m    831\u001b[0m         detected_sources \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    832\u001b[0m             importer(path, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    833\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m importer\u001b[38;5;241m.\u001b[39mcan_stream\n\u001b[0;32m--> 834\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mimporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     extractor_merger \u001b[38;5;241m=\u001b[39m importer\u001b[38;5;241m.\u001b[39mget_extractor_merger()\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m env\u001b[38;5;241m.\u001b[39mextractors:\n",
      "File \u001b[0;32m/local/sooahlee/datumaro/src/datumaro/components/importer.py:67\u001b[0m, in \u001b[0;36mImporter.__call__\u001b[0;34m(self, path, stream, **extra_params)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_params):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m osp\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNAME)\n\u001b[1;32m     69\u001b[0m     found_sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_sources_with_params(osp\u001b[38;5;241m.\u001b[39mnormpath(path), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_params)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found_sources:\n",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m: Failed to find dataset 'cifar' at 'cifar-100-python'"
     ]
    }
   ],
   "source": [
    "# Copyright (C) 2024 Intel Corporation\n",
    "#\n",
    "# SPDX-License-Identifier: MIT\n",
    "\n",
    "from copy import deepcopy\n",
    "from datumaro.components.dataset import Dataset\n",
    "\n",
    "# Assuming the CIFAR-100 dataset has been loaded and extracted\n",
    "# Initialize the dataset extractor\n",
    "dataset = Dataset.import_from(\"cifar-10-python\", format=\"cifar\")\n",
    "\n",
    "# Define the label list (CIFAR-10 classes)\n",
    "label_list = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "# Function to get the original label\n",
    "\n",
    "\n",
    "def get_ground_truth_label(item):\n",
    "    # Assuming that the dataset annotations include ground truth labels as the first annotation\n",
    "    return item.annotations[0].label\n",
    "\n",
    "\n",
    "original = deepcopy(dataset)\n",
    "# Initialize the PseudoLabeling class\n",
    "result = dataset.transform(\"pseudo_labeling\", labels=label_list)\n",
    "\n",
    "# Compare the pseudo-label and ground truth label\n",
    "for item in result.take(5):\n",
    "    # Get the pseudo-label from transformed dataset\n",
    "    pseudo_label = item.annotations[0].label\n",
    "\n",
    "    # Get the original ground truth label from the original dataset\n",
    "    original_item = original.get(item.id)\n",
    "    ground_truth_label = get_ground_truth_label(original_item)\n",
    "\n",
    "    print(f\"Item ID: {item.id}\")\n",
    "    print(f\"Ground Truth Label: {label_list[ground_truth_label]}\")\n",
    "    print(f\"Pseudo-label: {label_list[pseudo_label]}\")\n",
    "    print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "1. **Load the dataset**: We use `Dataset.import_from()` to load CIFAR-10 in the appropriate format.\n",
    "2. **Define labels**: A predefined list of 10 labels is passed, matching the CIFAR-10 classes.\n",
    "3. **Apply transformation**: The `pseudo_labeling` transformation is applied, generating pseudo-labels based on the similarity between the images and the label embeddings.\n",
    "4. **View results**: We print a few items from the resulting dataset along with their newly assigned pseudo-labels.\n",
    "\n",
    "This basic usage demonstrates how to use the feature with CIFAR-10, applying pseudo-labeling to unlabeled or partially labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation: Pseudo-Labeling Accuracy\n",
    "\n",
    "After assigning pseudo-labels to the dataset, it’s important to evaluate how well these pseudo-labels match the actual ground truth labels. One simple way to do this is by calculating the accuracy of the pseudo-labels compared to the true labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the accuracy of pseudo-labeling\n",
    "def evaluate_pseudo_labeling_accuracy(dataset, pseudo_labeled_dataset, label_list):\n",
    "    total_items = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Iterate through the original and pseudo-labeled datasets\n",
    "    for item in pseudo_labeled_dataset:\n",
    "        total_items += 1\n",
    "\n",
    "        # Get pseudo-label\n",
    "        pseudo_label = item.annotations[0].label\n",
    "\n",
    "        # Get ground truth label\n",
    "        original_item = dataset.get(item.id)\n",
    "        ground_truth_label = original_item.annotations[0].label\n",
    "\n",
    "        # Compare and count correct predictions\n",
    "        if pseudo_label == ground_truth_label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_items\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Calculate accuracy of the pseudo-labeling\n",
    "accuracy = evaluate_pseudo_labeling_accuracy(dataset, result, label_list)\n",
    "print(f\"Pseudo-Labeling Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Fine-tuning pseudo-labeling**: Depending on the results, you can adjust the pseudo-labeling process, such as changing the label list, experimenting with different datasets, or modifying the hashing method.\n",
    "- **Advanced applications**: Try applying this pseudo-labeling feature to a semi-supervised learning pipeline where some labels are available, but others need to be generated.\n",
    "- **Custom Explorers**: Experiment with custom `Explorer` implementations that use different techniques for hashing or similarity calculation to see how they impact pseudo-labeling performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
